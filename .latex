Suggested Papers/Sources for your "Background" Section (with arXiv where available):
For 2.1 Complexity (Game Complexity, PSPACE-completeness):
Foundational Text on Computational Complexity of Games:
Source: Games, Puzzles, and Computation by Erik D. Demaine and Robert A. Hearn.
Why: This is the definitive book on the computational complexity of games. Your existing references [3] and [4] (Hearn and Demaine) likely point to work from or related to this book. You should absolutely cite this book when discussing PSPACE-completeness of generalized board games.
How to find: Look up "Games, Puzzles, and Computation Demaine Hearn" on Google Scholar or a library database. A specific arXiv link might not be for the full book, but individual chapters or related papers may be there.
PSPACE-Completeness of Specific Games / Reduction from NCL:
Source: "PSPACE-Completeness of Sliding-Block Puzzles and Other Problems through the Nondeterministic Constraint Logic Model of Computation" by Robert A. Hearn and Erik D. Demaine. (This is already [3] in your references).
Why: Directly relevant as you mention reduction from NCL. You should cite this heavily in your PSPACE-Hardness proof (Section 4.2).
arXiv: Often available.
General Game Complexity Concepts:
Source: "Complexity Theory and Game Theory: An Introduction" (Various introductory chapters in textbooks on computational game theory).
Why: For general statements about game trees, state spaces, and the definition of PSPACE.
How to find: Search on Google Scholar for "computational game theory complexity introduction" or similar. Look for review articles or textbook chapters.
For 2.2 Randomness (Stochastic Games, Imperfect Information):
Stochastic Games:
Source: "Stochastic Games" by Lloyd S. Shapley (original paper, 1953) or modern reviews/textbook chapters.
Why: Introduces the concept of games with probabilistic transitions.
How to find: Search for "Stochastic Games Shapley" on Google Scholar. Modern textbooks on game theory or AI often have chapters on stochastic games.
Games with Imperfect Information (if relevant):
Source: "Game Theory: An Introduction" by Steven Tadelis, or "An Introduction to Game Theory" by Martin J. Osborne.
Why: For definitions and discussions of games where players don't know the full state (though your dice rolls are "perfect information" in that the roll itself is known, the outcome is uncertain). Your text emphasizes uncertainty, which relates to stochastic games.
How to find: Standard game theory textbooks.
For 2.3 Game AI Techniques (Heuristic Search, MCTS, Related Work):
Foundational AI Textbook:
Source: Artificial Intelligence: A Modern Approach by Stuart Russell and Peter Norvig. (This is already [5] in your references).
Why: This is the canonical textbook for AI. It will have chapters on:
Heuristic search (Minimax, Alpha-Beta pruning).
Game playing (general principles).
Stochastic games (expectiminimax).
How to find: Reference the book directly whenever you mention these techniques.
Monte Carlo Tree Search (MCTS):
Source: "Bandit based Monte-Carlo Planning" by Levente Kocsis and Csaba Szepesv√°ri (2006). This is often considered a seminal paper introducing UCT (Upper Confidence Bound 1), which is key to MCTS.
Why: Directly relevant as you use UCT.
arXiv: Often available if you search for the title and authors.
Related Work/Games (Chess, Go, Backgammon):
Source for Chess/Go AI: The Russell & Norvig book [5] will discuss these. For Go specifically, AlphaGo papers (DeepMind) would be relevant but might be too advanced for your level of detail. Stick to general AI game-playing discussions.
Source for Backgammon AI: "TD-Gammon, a self-teaching backgammon program" by Gerald Tesauro (1995).
Why: Seminal work showing reinforcement learning's power in games with randomness.
How to find: Search on Google Scholar.
Action Plan for You:


\subsection{Results}
The development and analysis of Kings of the West yielded several significant results across its different components. We successfully implemented a fully functional browser-based game, complete with a user-friendly interface and adherence to the defined game mechanics.

From an Artificial Intelligence perspective, two distinct agents were developed: a heuristic-based Easy AI and a more sophisticated Monte Carlo Tree Search (MCTS) AI. Preliminary testing indicates that the MCTS agent demonstrates a significantly stronger understanding of long-term strategic play compared to the greedy, immediate-reward-focused Easy AI. While comprehensive comparative statistics are still being gathered, the MCTS AI consistently provides a more challenging opponent for human players and the Easy AI.

Our computational complexity analysis, focusing on the ``Generalized Kings of the West'' played on an N $\times$ M board, established that determining optimal play in this game is PSPACE-complete. This was achieved by demonstrating both membership in PSPACE, through the existence of a polynomial-space algorithm (such as Minimax search with pruning), and PSPACE-Hardness, via a reduction from Nondeterministic Constraint Logic (NCL) by constructing blocking and threat gadgets within the game's mechanics.

A summary of the AI characteristics and complexity findings is presented in Table \ref{tab:results_summary}.

\begin{table}[h!]
    \centering
    \caption{Summary of AI Characteristics and Complexity Findings}
    \label{tab:results_summary}
    \begin{tabular}{p{0.2\textwidth} p{0.4\textwidth} p{0.3\textwidth}}
        \toprule
        \textbf{Feature/AI Agent} & \textbf{Description} & \textbf{Observed Performance / Complexity Implications} \\
        \midrule
        \textbf{Game Complexity} & Generalized Kings of the West (N $\times$ M board) & PSPACE-complete (Optimal play decision) \\
        \textbf{Easy AI} & Heuristic-based, greedy agent using \texttt{evaluateAction} & Stronger than random, but prone to short-sightedness \\
        \textbf{MCTS AI} & Monte Carlo Tree Search with \texttt{randomPlayout} and UCT selection & Provides a challenging opponent, learns from simulations \\
        \bottomrule
    \end{tabular}
\end{table}